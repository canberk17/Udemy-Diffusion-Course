{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOnawdLYnGJs1HrsXOMcMK4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V0zY0F5GlGnG","executionInfo":{"status":"ok","timestamp":1688419903913,"user_tz":420,"elapsed":118467,"user":{"displayName":"Canberk Kandemir","userId":"18419208864442465365"}},"outputId":"58b4d8c9-2b39-43cf-967a-aa742fe7edb8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch==1.13.1\n","  Downloading torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.5/887.5 MB\u001b[0m \u001b[31m806.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1) (4.6.3)\n","Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==1.13.1)\n","  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch==1.13.1)\n","  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch==1.13.1)\n","  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==1.13.1)\n","  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (67.7.2)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (0.40.0)\n","Installing collected packages: nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, nvidia-cudnn-cu11, torch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.0.1+cu118\n","    Uninstalling torch-2.0.1+cu118:\n","      Successfully uninstalled torch-2.0.1+cu118\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\n","torchdata 0.6.1 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\n","torchtext 0.15.2 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\n","torchvision 0.15.2+cu118 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 torch-1.13.1\n"]}],"source":["!pip install torch==1.13.1"]},{"cell_type":"code","source":["import torch\n","torch.__version__"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"i_I04PTgop6k","executionInfo":{"status":"ok","timestamp":1688419905427,"user_tz":420,"elapsed":1518,"user":{"displayName":"Canberk Kandemir","userId":"18419208864442465365"}},"outputId":"ae0586e2-b66a-407e-dfbc-0f081bda5801"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'1.13.1+cu117'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["#Installs CLIP\n","!git clone https://github.com/openai/CLIP                 &> /dev/null\n","\n","#Installs Python Libraries for AI\n","!git clone https://github.com/CompVis/taming-transformers &> /dev/null\n","!pip install transformers                                 &> /dev/null\n","!pip install ftfy regex tqdm omegaconf pytorch-lightning  &> /dev/null\n","!pip install kornia                                       &> /dev/null\n","!pip install einops                                       &> /dev/null\n","!pip install wget                                         &> /dev/null\n","\n","#Installs libraries for metadata management\n","!pip install stegano                                      &> /dev/null\n","!apt install exempi                                       &> /dev/null\n","!pip install python-xmp-toolkit                           &> /dev/null\n","!pip install imgtag                                       &> /dev/null\n","!pip install pillow==7.1.2                                &> /dev/null\n","\n","#Installs Python libraries for creating videos\n","!pip install imageio-ffmpeg                               &> /dev/null\n","!mkdir steps\n","\n","print(\"Installation completed!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VhuCGQOMorVL","executionInfo":{"status":"ok","timestamp":1688420019972,"user_tz":420,"elapsed":114547,"user":{"displayName":"Canberk Kandemir","userId":"18419208864442465365"}},"outputId":"ae8bec44-53cd-4734-d4fe-58a188b6d689"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Installation completed!\n"]}]},{"cell_type":"code","source":["#downloads imagenet_1024:\n","!curl -L -o vqgan_imagenet_f16_1024.yaml -C - 'https://heibox.uni-heidelberg.de/d/8088892a516d4e3baf92/files/?p=%2Fconfigs%2Fmodel.yaml&dl=1'\n","!curl -L -o vqgan_imagenet_f16_1024.ckpt -C - 'https://heibox.uni-heidelberg.de/d/8088892a516d4e3baf92/files/?p=%2Fckpts%2Flast.ckpt&dl=1'\n","\n","#downloads imagenet_16384:\n","!curl -L -o vqgan_imagenet_f16_16384.yaml -C - 'https://heibox.uni-heidelberg.de/d/a7530b09fed84f80a887/files/?p=%2Fconfigs%2Fmodel.yaml&dl=1'\n","!curl -L -o vqgan_imagenet_f16_16384.ckpt -C - 'https://heibox.uni-heidelberg.de/d/a7530b09fed84f80a887/files/?p=%2Fckpts%2Flast.ckpt&dl=1'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QId3AlGjosUB","outputId":"ad7f9fea-9652-4de4-e54c-e95a20ea844b","executionInfo":{"status":"ok","timestamp":1688420146179,"user_tz":420,"elapsed":126224,"user":{"displayName":"Canberk Kandemir","userId":"18419208864442465365"}}},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n","100   645  100   645    0     0    818      0 --:--:-- --:--:-- --:--:--   818\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n","100  913M  100  913M    0     0  14.8M      0  0:01:01  0:01:01 --:--:-- 14.9M\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n","100   692  100   692    0     0    946      0 --:--:-- --:--:-- --:--:--   946\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n","100  934M  100  934M    0     0  14.8M      0  0:01:02  0:01:02 --:--:-- 14.9M\n"]}]},{"cell_type":"code","source":["from pathlib import Path\n","import argparse\n","import math\n","import sys"],"metadata":{"id":"QyOztgy5otlU","executionInfo":{"status":"ok","timestamp":1688420146179,"user_tz":420,"elapsed":3,"user":{"displayName":"Canberk Kandemir","userId":"18419208864442465365"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["sys.path.append('./taming-transformers')"],"metadata":{"id":"v9EzcuyVou7P","executionInfo":{"status":"ok","timestamp":1688420146179,"user_tz":420,"elapsed":3,"user":{"displayName":"Canberk Kandemir","userId":"18419208864442465365"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["from vq_helper_functions import"],"metadata":{"id":"WAGM6eOFov1-","colab":{"base_uri":"https://localhost:8080/","height":312},"executionInfo":{"status":"error","timestamp":1688420787248,"user_tz":420,"elapsed":5,"user":{"displayName":"Canberk Kandemir","userId":"18419208864442465365"}},"outputId":"16a95677-8922-442f-a76e-47b4f3c70438"},"execution_count":14,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-652a87d99924>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvq_helper_functions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdownload_img\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mload_vqgan_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'vq_helper_functions'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["texts = \"a fantasy kingdom\"\n","width, height = 300, 300\n","model = 'vqgan_imagenet_f16_16384'\n","images_interval = 50\n","init_image = \"\"\n","target_images = \"\"\n","seed = 1305229777650133088\n","max_iterations = 700\n","input_images = \"\"\n","\n","model_names = {\"vqgan_imagenet_f16_16384\": 'ImageNet 16384',\n","               \"vqgan_imagenet_f16_1024\": 'ImageNet 1024'}\n","model_name = model_names[model]\n","\n","if seed == -1:\n","  seed = None\n","\n","if init_image == \"None\":\n","  init_image = None\n","elif init_image and init_image.lower().startswith(\"http\"):\n","  init_image = download_img(init_image)\n","\n","if target_images == \"None\" or not target_images:\n","    target_images = []\n","else:\n","    target_images = target_images.split(\"|\")\n","    target_images = [image.strip() for image in target_images]\n","\n","if init_image or target_images != []:\n","    input_images = True\n","\n","texts = [sentence.strip() for sentence in texts.split(\"|\")]\n","if texts == ['']:\n","    texts = []"],"metadata":{"id":"nVuR9fqrow1c","executionInfo":{"status":"ok","timestamp":1688420369241,"user_tz":420,"elapsed":2,"user":{"displayName":"Canberk Kandemir","userId":"18419208864442465365"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["args = argparse.Namespace(\n","    prompts=texts,\n","    image_prompts=target_images,\n","    noise_prompt_seeds=[],\n","    noise_prompt_weights=[],\n","    size=[width, height],\n","    init_image=init_image,\n","    init_weight=0.,\n","    clip_model='ViT-B/32',\n","    vqgan_config=f'{model}.yaml',\n","    vqgan_checkpoint=f'{model}.ckpt',\n","    step_size=0.1,\n","    cutn=64,\n","    cut_pow=1.,\n","    display_freq=images_interval,\n","    seed=seed\n",")\n","args"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GGVCPWGGskI1","executionInfo":{"status":"ok","timestamp":1688420594327,"user_tz":420,"elapsed":2,"user":{"displayName":"Canberk Kandemir","userId":"18419208864442465365"}},"outputId":"5dd37093-d49a-4082-eb85-b75f886e0760"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Namespace(prompts=['a fantasy kingdom'], image_prompts=[], noise_prompt_seeds=[], noise_prompt_weights=[], size=[300, 300], init_image='', init_weight=0.0, clip_model='ViT-B/32', vqgan_config='vqgan_imagenet_f16_16384.yaml', vqgan_checkpoint='vqgan_imagenet_f16_16384.ckpt', step_size=0.1, cutn=64, cut_pow=1.0, display_freq=50, seed=1305229777650133088)"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["!nvidia-smi -caa # Delete memory from previous runs\n","\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","print('Using device:', device)\n","if texts:\n","    print('Using text prompt:', texts)\n","if target_images:\n","    print('Using image prompts:', target_images)\n","if args.seed is None:\n","    seed = torch.seed()\n","else:\n","    seed = args.seed\n","torch.manual_seed(seed)\n","print('Using seed:', seed)\n","\n","\n","model = load_vqgan_model(args.vqgan_config, args.vqgan_checkpoint).to(device)\n","perceptor = clip.load(args.clip_model, jit=False)[0].eval().requires_grad_(False).to(device)\n","\n","cut_size = perceptor.visual.input_resolution\n","e_dim = model.quantize.e_dim\n","f = 2**(model.decoder.num_resolutions - 1)\n","make_cutouts = MakeCutouts(cut_size, args.cutn, cut_pow=args.cut_pow)\n","n_toks = model.quantize.n_e\n","toksX, toksY = args.size[0] // f, args.size[1] // f\n","sideX, sideY = toksX * f, toksY * f\n","z_min = model.quantize.embedding.weight.min(dim=0).values[None, :, None, None]\n","z_max = model.quantize.embedding.weight.max(dim=0).values[None, :, None, None]\n","\n","\n","if args.init_image:\n","    pil_image = Image.open(args.init_image).convert('RGB')\n","    pil_image = pil_image.resize((sideX, sideY), Image.LANCZOS)\n","    z, *_ = model.encode(TF.to_tensor(pil_image).to(device).unsqueeze(0) * 2 - 1)\n","else:\n","    one_hot = F.one_hot(torch.randint(n_toks, [toksY * toksX], device=device), n_toks).float()\n","    z = one_hot @ model.quantize.embedding.weight\n","    z = z.view([-1, toksY, toksX, e_dim]).permute(0, 3, 1, 2)\n","z_orig = z.clone()\n","z.requires_grad_(True)\n","opt = optim.Adam([z], lr=args.step_size)\n","\n","normalize = transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073],\n","                                 std=[0.26862954, 0.26130258, 0.27577711])\n","\n","pMs = []\n","\n","for prompt in args.prompts:\n","    txt, weight, stop = parse_prompt(prompt)\n","    embed = perceptor.encode_text(clip.tokenize(txt).to(device)).float()\n","    pMs.append(Prompt(embed, weight, stop).to(device))\n","\n","for prompt in args.image_prompts:\n","    path, weight, stop = parse_prompt(prompt)\n","    img = resize_image(Image.open(path).convert('RGB'), (sideX, sideY))\n","    batch = make_cutouts(TF.to_tensor(img).unsqueeze(0).to(device))\n","    embed = perceptor.encode_image(normalize(batch)).float()\n","    pMs.append(Prompt(embed, weight, stop).to(device))\n","\n","for seed, weight in zip(args.noise_prompt_seeds, args.noise_prompt_weights):\n","    gen = torch.Generator().manual_seed(seed)\n","    embed = torch.empty([1, perceptor.visual.output_dim]).normal_(generator=gen)\n","    pMs.append(Prompt(embed, weight).to(device))\n","\n","def synth(z):\n","    z_q = vector_quantize(z.movedim(1, 3), model.quantize.embedding.weight).movedim(3, 1)\n","    return clamp_with_grad(model.decode(z_q).add(1).div(2), 0, 1)\n","\n","def add_xmp_data(nombrefichero):\n","    image = ImgTag(filename=nombrefichero)\n","    image.xmp.append_array_item(libxmp.consts.XMP_NS_DC, 'creator', 'VQGAN+CLIP', {\"prop_array_is_ordered\":True, \"prop_value_is_array\":True})\n","    if args.prompts:\n","        image.xmp.append_array_item(libxmp.consts.XMP_NS_DC, 'title', \" | \".join(args.prompts), {\"prop_array_is_ordered\":True, \"prop_value_is_array\":True})\n","    else:\n","        image.xmp.append_array_item(libxmp.consts.XMP_NS_DC, 'title', 'None', {\"prop_array_is_ordered\":True, \"prop_value_is_array\":True})\n","    image.xmp.append_array_item(libxmp.consts.XMP_NS_DC, 'i', str(i), {\"prop_array_is_ordered\":True, \"prop_value_is_array\":True})\n","    image.xmp.append_array_item(libxmp.consts.XMP_NS_DC, 'model', model_name, {\"prop_array_is_ordered\":True, \"prop_value_is_array\":True})\n","    image.xmp.append_array_item(libxmp.consts.XMP_NS_DC, 'seed',str(seed) , {\"prop_array_is_ordered\":True, \"prop_value_is_array\":True})\n","    image.xmp.append_array_item(libxmp.consts.XMP_NS_DC, 'input_images',str(input_images) , {\"prop_array_is_ordered\":True, \"prop_value_is_array\":True})\n","    #for frases in args.prompts:\n","    #    image.xmp.append_array_item(libxmp.consts.XMP_NS_DC, 'Prompt' ,frases, {\"prop_array_is_ordered\":True, \"prop_value_is_array\":True})\n","    image.close()\n","\n","def add_stegano_data(filename):\n","    data = {\n","        \"title\": \" | \".join(args.prompts) if args.prompts else None,\n","        \"notebook\": \"VQGAN+CLIP\",\n","        \"i\": i,\n","        \"model\": model_name,\n","        \"seed\": str(seed),\n","        \"input_images\": input_images\n","    }\n","    lsb.hide(filename, json.dumps(data)).save(filename)\n","\n","@torch.no_grad()\n","def checkin(i, losses):\n","    losses_str = ', '.join(f'{loss.item():g}' for loss in losses)\n","    tqdm.write(f'i: {i}, loss: {sum(losses).item():g}, losses: {losses_str}')\n","    out = synth(z)\n","    TF.to_pil_image(out[0].cpu()).save('progress.png')\n","    add_stegano_data('progress.png')\n","    add_xmp_data('progress.png')\n","    display.display(display.Image('progress.png'))\n","\n","def ascend_txt():\n","    global i\n","    out = synth(z)\n","    iii = perceptor.encode_image(normalize(make_cutouts(out))).float()\n","\n","    result = []\n","\n","    if args.init_weight:\n","        result.append(F.mse_loss(z, z_orig) * args.init_weight / 2)\n","\n","    for prompt in pMs:\n","        result.append(prompt(iii))\n","    img = np.array(out.mul(255).clamp(0, 255)[0].cpu().detach().numpy().astype(np.uint8))[:,:,:]\n","    img = np.transpose(img, (1, 2, 0))\n","    filename = f\"steps/{i:04}.png\"\n","    imageio.imwrite(filename, np.array(img))\n","    add_stegano_data(filename)\n","    add_xmp_data(filename)\n","    return result\n","\n","def train(i):\n","    opt.zero_grad()\n","    lossAll = ascend_txt()\n","    if i % args.display_freq == 0:\n","        checkin(i, lossAll)\n","    loss = sum(lossAll)\n","    loss.backward()\n","    opt.step()\n","    with torch.no_grad():\n","        z.copy_(z.maximum(z_min).minimum(z_max))\n","\n","i = 0\n","try:\n","    with tqdm() as pbar:\n","        while True:\n","            train(i)\n","            if i == max_iterations:\n","                break\n","            i += 1\n","            pbar.update()\n","except KeyboardInterrupt:\n","    pass"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":329},"id":"vrcVfRnqtbFE","executionInfo":{"status":"error","timestamp":1688420814266,"user_tz":420,"elapsed":315,"user":{"displayName":"Canberk Kandemir","userId":"18419208864442465365"}},"outputId":"d96a0519-1cc0-49ee-b418-d3dfc9c48fe1"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Cleared Accounted PIDs for GPU 00000000:00:04.0.\n","All done.\n","Using device: cuda:0\n","Using text prompt: ['a fantasy kingdom']\n","Using seed: 1305229777650133088\n"]},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-0a328cc7fa03>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_vqgan_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvqgan_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvqgan_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mperceptor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'load_vqgan_model' is not defined"]}]},{"cell_type":"code","source":[],"metadata":{"id":"CO-ipG_Nt53H"},"execution_count":null,"outputs":[]}]}